## 선형분류의 목표와 방법들

#### 분류(classification)의 목표

- 입력벡터 x를 K개의 가능한 클래스 중에서 하나의 클래스로 할당하는 것

분류를 위한 결정이론

- 확률적 모델
  - 생성모델: p(x|C<sub>k</sub>)와 p(C<sub>k</sub>)를 모델링한 다음 베이즈 정리를 사용해서 클래스의 사후 확률 p(C<sub>k</sub>|x)를 구한다. 또는 결합확률 p(x|C<sub>k</sub>)를 직접 모델링할 수도 있다.
  - 식별모델: p(C<sub>k</sub>|x)를 직접적으로 모델링한다.
- 판별함수: 입력 x를 클래스로 할당하는 판별함수를 찾는다. 확률값은 계산하지 않는다.

#### 판별함수(Discriminant Functions)

- 입력 x를 클래스로 할당하는 판별함수를 찾고자 한다. 여기서는 그러한 함수 중 선형함수만을 다룰 것이다.

![image](https://user-images.githubusercontent.com/60081212/121456602-4a853300-c9e1-11eb-9976-8842b1909e9d.png)

![image](https://user-images.githubusercontent.com/60081212/121456704-70aad300-c9e1-11eb-82a9-af98ab9633c5.png)

![image](https://user-images.githubusercontent.com/60081212/121457875-5c67d580-c9e3-11eb-80ba-92ccd2e05fae.png)

#### 다수의 클래스

![image](https://user-images.githubusercontent.com/60081212/121458057-a486f800-c9e3-11eb-81e2-b3d6b28dae8d.png)



#### 분류를 위한 최소제곱법(Least Squares for classification)

![image](https://user-images.githubusercontent.com/60081212/121458289-10696080-c9e4-11eb-8acc-4266fd952eb5.png)

#### 제곱합 에러 함수

![image](https://user-images.githubusercontent.com/60081212/121458541-84a40400-c9e4-11eb-8eef-42447ee50f82.png)

![image](https://user-images.githubusercontent.com/60081212/121458605-a00f0f00-c9e4-11eb-861b-fcd8f7fcae47.png)

![image](https://user-images.githubusercontent.com/60081212/121458624-a9987700-c9e4-11eb-952f-4f7be301999a.png)

#### 분류를 위한 최소제곱법의 문제들

- 극단치(outlier)에 민감하다.

- 목표값의 확률분포에 대한 잘못된 가정에 기초해 있다.

  - 목표값이 가우시안 분포를 따른다는 가정 하에 최소제곱법을 이용한는데, 목표값이 가우시안을 따르지 않기 때문에 결과가 잘 나오지 않는다.

  ![image](https://user-images.githubusercontent.com/60081212/121458750-e5334100-c9e4-11eb-9082-84e86b973ef1.png)

#### 퍼셉트론 알고리즘(The perceptron algorithm)

![image](https://user-images.githubusercontent.com/60081212/121459162-b4074080-c9e5-11eb-85cf-0d4a0ebba39a.png)

![image](https://user-images.githubusercontent.com/60081212/121459337-05afcb00-c9e6-11eb-9a26-b5f3dc31c327.png)

#### 확률적 생성 모델(Probabilistic generative models)

- 이제 분류문제를 확률적 관점에서 살펴보고자 한다. 선형회귀와 마찬가지로 확률적 모델은 통합적인 관점을 제공해준다. 예를 들어 데이터의 분포에 관해 어떤 가정을 두게 되면 앞에서 살펴본 선형적인 결정경계(linear decision boundary)가 그 결과로 유도되는 것을 보게 될 것이다.
- p(x|C<sub>k</sub>)와 p(C<sub>k</sub>)를 모델링한다음 베이즈 정리를 사용해서 클래스의 사후 확률 p(C<sub>k</sub>|x)를 구한다. 이전의 판별함수 방법에서는 어떤 에러함수를 최소화시키기 위한 최적의 파라미터를 찾는 것이 목적이라면 확률적 모델은 데이터의 분포(클래스를 포함한)를 모델링하면서 분류문제를 결과적으로 풀게 된다.

![image](https://user-images.githubusercontent.com/60081212/121459773-d0f04380-c9e6-11eb-94a2-21352e76d21c.png)

#### Logistic sigmoid의 성질 및 역함수

![image-20210610122821212](C:\Users\a\AppData\Roaming\Typora\typora-user-images\image-20210610122821212.png)

#### 연속적 입력(continous inputs)

- 가우시안 분포를 따르고, 공분산이 동일하다는 가정!

![image](https://user-images.githubusercontent.com/60081212/121460432-dc903a00-c9e7-11eb-925d-9cd0f9281362.png)

![image](https://user-images.githubusercontent.com/60081212/121460488-f6318180-c9e7-11eb-9251-b8168fa28c5a.png)

#### 최대우도해(Maximum likelihood solution)

- 이제 MLE를 통해 모델 파라미터들을 구해보자. 두 개의 클래스인 경우를 살펴본다.

![image](https://user-images.githubusercontent.com/60081212/121460583-20833f00-c9e8-11eb-8ede-ee8e091293ef.png)



![image](https://user-images.githubusercontent.com/60081212/121460843-a56e5880-c9e8-11eb-9233-95803980ec49.png)



![image](https://user-images.githubusercontent.com/60081212/121460938-d3539d00-c9e8-11eb-924e-787874f092e7.png)



![image](https://user-images.githubusercontent.com/60081212/121461107-2d546280-c9e9-11eb-90ec-365d3e7aae04.png)

### 복습 - 가우시안 분포의 최대우도

![image](https://user-images.githubusercontent.com/60081212/121461150-43622300-c9e9-11eb-90c8-e5b82c645949.png)

#### 입력이 이산값일 경우(Discrete features)

- 각 특성 x<sub>i</sub>가 0과 1 중 하나의 값만을 가질 수 있는 경우

- 클래스가 주어졌을 때 특성들이 조건부독립(conditional independence)이라는 가정을 할 경우 문제는 단순화된다. 이것을 naive Bayes가정이라고 한다. 이 때 p(x|C<sub>k</sub>)는 다음과 같이 분해된다.

  ​		![image](https://user-images.githubusercontent.com/60081212/121461373-ac499b00-c9e9-11eb-9ffa-3d0e13465e14.png)

#### 확률적 식별 모델(Probabilistic discriminative models)

![image](https://user-images.githubusercontent.com/60081212/121461504-f7fc4480-c9e9-11eb-8ba4-fdc4552723c4.png)

#### 로지스틱 회귀(Logistic regression)

![image](https://user-images.githubusercontent.com/60081212/121461563-0ea29b80-c9ea-11eb-95cf-5b6a89ac1b94.png)



#### 최대우도해

![image](https://user-images.githubusercontent.com/60081212/121461832-925c8800-c9ea-11eb-800c-bdfe5e7c52eb.png)

![image-20210610125214712](C:\Users\a\AppData\Roaming\Typora\typora-user-images\image-20210610125214712.png)

