## 신경망의 기초 - 다층퍼셉트론

#### 인공신경망

- 기계학습 역사에서 가장 오래된 기계 학습 모델
  - 1950년대 퍼셉트론(인공두뇌학)
  - 1980년대 다층 퍼셉트론(결합설)
  - 2000년대 깊은 인공신경망(심층학습)
- 현재 다양한 형태의 인공신경망을 가지며, 주목할 만한 결과를 제공함
  - 3장은 깊은 인공신경망(심층학습)의 기초가 됨



- 사람의 뉴런

  - 두뇌의 가장 작은 정보처리 단위

- 구조

  - 세포체는 간단한 연산
  - 수상돌기는 신호 수신
  - 축삭은 처리 결과를 전송

- 사람은 10<sup>11</sup>개 정도의 뉴런을 가지며, 각 뉴런은 약 1000개의 다른 뉴런과 연결되어 10<sup>14</sup>개 연결을 가짐
  ![image](https://user-images.githubusercontent.com/60081212/122693487-0877af00-d275-11eb-87f2-64a10102143d.png)

- 두 줄기 연구의 동반상승 효과

  - 컴퓨터 과학

    - 컴퓨터의 계산(연산) 능력의 획기적 발전

  - 뇌(의학) 과학

    - 뇌의 정보처리 방식 규명 연구

  - 컴퓨터가 사람 뇌의 정보처리를 모방하여 지능적 행위를 할 수 있는 인공지능 도전

    - 뉴런의 동작 이해를 모방한 초기 인공 신경망(ANN_artificial neural networks) 연구 시작

    -> 퍼셉트론 고안

- 사람의 신경망과 인공신경망 비교
  ![image](https://user-images.githubusercontent.com/60081212/122693550-4c6ab400-d275-11eb-873e-f717858a85f6.png)

- 신경망의 역사
  ![image-20210621094605889](https://user-images.githubusercontent.com/60081212/122693647-9b184e00-d275-11eb-86f8-152e2487be21.png)

- 인공신경망은 다양한 모델이 존재함
  - 전방 신경망과 순환 신경망
  - 얕은 신경망과 깊은 신경망
    ![image-20210621094635153](https://user-images.githubusercontent.com/60081212/122693657-a66b7980-d275-11eb-95cf-ecd0b9218e61.png)

- 결정론적 신경망과 확률론적 신경망 비교

  - 결정론 신경망
    - 모델의 매개변수와 조건에 의해 출력이 완전히 결전되는 신경망
  - 확률론적 신경망
    - 고유의 임의성을 가지고 매개면수와 조건이 같더라도 다른 출력을 가지는 신경망

  ![image](https://user-images.githubusercontent.com/60081212/122693802-53de8d00-d276-11eb-91b9-b5603210bfef.png)

- 다양한 신경망 구조
  ![image-20210621095223796](C:\Users\a\AppData\Roaming\Typora\typora-user-images\image-20210621095223796.png)

- 구조: 절, 가중치, 층 과 같은 새로운 개념의 구조 도입

- 제시된 퍼셉트론 구조의 학습 알고리즘을 제안

- 원시적 신경망이지만, 깊은 인공신경망을 포함한 현대 인공신경망의 토대

  - 깊은 인공신경망은 퍼셉트론의 병렬 배치를 순차적인 구조로 결합함

  -> 현대 인공신경망의 중요한 구성 요소가 됨

- 퍼셉트론의 구조

  ![image](https://user-images.githubusercontent.com/60081212/122693891-9dc77300-d276-11eb-8508-92de3c880fba.png)

- 퍼셉트론의 동작

  - 선형 연산 -> 비선형 연산

    - [선형] 입력(특징) 값과 가충치를 곱하고 모두 더해 s를 구함

    - [비선형] 활성함수 τ를 적용

      -활성함수 τ로 계단함수를 사용 -> 출력 y=+1 or y=-1

  - 수식

    ![image](https://user-images.githubusercontent.com/60081212/122694135-64433780-d277-11eb-8bfb-e66d902d4f1a.png)

![image](https://user-images.githubusercontent.com/60081212/122695099-678bf280-d27a-11eb-915a-4361d9424513.png)

![image](https://user-images.githubusercontent.com/60081212/122695192-ab7ef780-d27a-11eb-91d6-d5001bc864a2.png)

![image](https://user-images.githubusercontent.com/60081212/122695262-d9643c00-d27a-11eb-90f6-3f1ad632e64b.png)

![image](https://user-images.githubusercontent.com/60081212/122695454-5f808280-d27b-11eb-97f1-faacc66013a7.png)

- 일반적인 분류기의 학습 과정
  - 단계1 : 과업 정의와 분류 과정의 수학적 정의(가설 가정)
  - 단계2 : 해당 분류기의 목적함수 J(Θ) 정의
  - 단계3 : J(Θ)를 최소화하는 Θ를 찾기 위한 최적화 방법 수행

![image](https://user-images.githubusercontent.com/60081212/122695561-af5f4980-d27b-11eb-9310-700347169a0d.png)

![image](https://user-images.githubusercontent.com/60081212/122695619-e2094200-d27b-11eb-9071-e60439337597.png)

![image](https://user-images.githubusercontent.com/60081212/122695802-6cea3c80-d27c-11eb-8e61-5d3369b398c5.png)

![image](https://user-images.githubusercontent.com/60081212/122695880-a0c56200-d27c-11eb-80dd-8ec4dda914a9.png)

![image](https://user-images.githubusercontent.com/60081212/122696017-fac62780-d27c-11eb-858d-72b364359123.png)

![image](https://user-images.githubusercontent.com/60081212/122696061-1af5e680-d27d-11eb-871a-004b01928140.png)

![image](https://user-images.githubusercontent.com/60081212/122696218-92c41100-d27d-11eb-8d2c-163634f1d489.png)

![image](https://user-images.githubusercontent.com/60081212/122696443-023a0080-d27e-11eb-8e77-174f790ff163.png)

![image](https://user-images.githubusercontent.com/60081212/122696462-0f56ef80-d27e-11eb-83a0-1a08d9321d5c.png)

![image](https://user-images.githubusercontent.com/60081212/122696508-2eee1800-d27e-11eb-99d6-53225cf7c61e.png)

![image](https://user-images.githubusercontent.com/60081212/122696612-75dc0d80-d27e-11eb-84d1-014e8110405c.png)

