## 벡터와 직교분해

벡터의 내적

- 좌표계 X
  - u · v = ||u|| ||v|| cosθ
- 좌표계
  - u · v = u<sub>1</sub>v<sub>1</sub> + ... + u<sub>n</sub>v<sub>n</sub>



두 벡터 u, v 간의 내적이 0이면 두 벡터는 직교(orthogonal)이다.



##### 직교의 물리적 의미

u와 v가 직교할 때, u 방향으로의 전진은 v 방향에서는 전혀 측정되지 않는다. 그 반대도 마찬가지이다.

(xy or xyz 좌표계가 직교좌표계였다.)



### 투영

두 벡터 u, a가 있을 때, 벡터  u를 a위에 투영한 벡터를 proj<sub>a</sub>**u** 라 하고 다음과 같이 구한다.

- proj<sub>a</sub>**u** = (**u** · **a** / ||**a**||<sup>2</sup>) **a**

벡터  u를 a위에 투영하고 남은 보완 벡터(complemtent vector)는 **u** - proj<sub>a</sub>**u** 다.

##### 투영과 보완 벡터는 직교

##### 투영 + 보완벡터 = 원래 벡터



### 직교행렬(Orthogonal Matrix): 직교좌표계에 대한 행렬 표현

ㅎ행렬은 좌표계라는 의미를 이미 배웠다. 즉, 행렬은 각 열벡터가 기저(basis)를 이루는 좌표계(coordinate system)이다.

##### 직교행렬(orthogonal matrix)

주어진 행렬의 모든 열벡터가 서로 직교한다면, 이 행렬은 직교행렬 - 직교좌표계를 의미.

##### 정규직교행렬(orthonormal matrix)

주어진 행렬이 직교행렬이고, 모든 열벡터의 크기가 1이라면 이 행렬을 정규직교행렬 - 정규직교좌표계 의미.



#### 직교행렬을 이용한 선형시스템

선형시스템 Ax = b에서 행렬 A가 직교행렬이면, 해 x는 역행렬 A<sup>-1</sup>의 계산 없이 다음과 같이 구할 수 있다.

- x의 i번째 요소는 투영으로 계산할 수 있다. 즉, 벡터 b를 행렬 A의 각 열벡터 a<sub>i</sub>에 투영한 연산 proj<sub>a<sub>i</sub></sub>**b**임을 계산할 수 있다.
- x의 i번째 요소와 j번째 요소의 계산은 독립적이다. 즉, x의 계산은 `병렬처리` 가능하다.

### -> 직교행렬일 경우, 계산(내적 및 스칼라 등의)만으로 해를 구할 수 있다.



#### 정규직교행렬을 이용한 선형시스템

선형시스템 Ax = b에서 행렬 A가 정규직교행렬이면, 해 x는 역행렬 A<sup>-1</sup>의 계산 없이 다음과 같이 구할 수 있다.

- x의 i번째 요소는 내적(inner product)으로 계산할 수 있다. 즉, 벡터  b를 행렬 A의 각 열벡터 a<sub>i</sub>에 투영한 연산  proj<sub>a<sub>i</sub></sub>**b**임을 계산할 수 있다.
- x의 i번째 요소와 j번째 요소의 계산은 독립적이다. 즉, x의 계산은 `병렬처리` 가능하다.



### QR분해: A = QR	주어진 행렬에서 정규직교행렬 추출

QR분해는 주어진 행렬을 Q(정규직교행렬)과 R(상삼각행렬)의 곱으로 나누는 행렬분해

Ax = b -> (QR)x = b -> Q(Rx) = b -> Qy = b(단, Rx = y) 의 과정을 통해 변환 후,

1. 내적을 통해 y구하기
2. 후방대치법을 통해 x구하기(Rx = y)에서 R은 상삼각행렬이므로

##### QR분해는 그람-슈미트 과정을 행렬로 코드화 한 것.



##### QR 분해의 활용

- 빠른 계산 : 선형시스템 Ax = b의 해를 구할 때, 정규직교행렬 Q를 이용한 계산 부분은 병렬처리로 빨리 계산할 수 있다. 그러나 R을 이용한 계산 부분은 병렬처리 할 수 없다.
- b가 자주 업데이트 되는 경우: 선형시스템 Ax = b에서 행렬 A는 고정되어 있고, b가 자주 변하는 문제일 때, 행렬 A를 미리 QR로 분해해 둔다면, b가 업데이트될 때마다 선형시스템의 해 x를 실시간으로 구할 수 있다.

##### QR분해 vs LU 분해

- LU 분해의 경우, 선형시스템을 풀 때 병렬처리 할 수 없다.
- QR분해의 경우, Q행렬이 꽉찬 구조를 가진 행렬이므로 메모리 사용량이 많다.





## 특이값 분해(SVD, Singular Value Decomposition)

LU분해와 QR분해는 n x n 정방행렬에 대한 행렬분해인 반면, 특이값 분해는 일반적인 m x n 행렬에 관한 분해

특이값 분해는 직교분할, 확대축소, 차원변환 등과 관련



특이밗 분해는 세 행렬의 곱으로 나누는 행렬분해

A = U D V

- U: m차원 회전행렬(정규직교행렬)	(열벡터)
- D: n차원 확대축소(확대축소 크기에 따른 정렬 형태)
- V: n차원 회전행렬(정규직교행렬)      (행벡터)



특이값 분해는 행렬을 회전과 확대축소로 분해하는 방법.

- U: 입력 차원인 R<sup>m</sup> 공간에서의 회전
- D: 입력 차원인 R<sup>m</sup> 공간에 대해 축방향으로의 확대축소한 후, R<sup>n</sup> -> R<sup>m</sup>으로 차원 변환
- V: 입력 차원인 R<sup>n</sup> 공간에서의 회전



##### 특이값 분해의 활용 -> 데이터의 중요한 부분만을 취한다.

A의 특이값 분해 U, D, V는 각각 열벡터의 순서대로 행렬 A의 열벡터가 어떤 방향으로 강한 응집성을 보이고 있는지를 분석한 것.

U, D, V의 열벡터를 순서대로 p개 취한다면, 강한 응집성을 가지는 p개의 방향으로 수선의 발을 내린 A의 근사치 A`을 재구성할 수 있다.



#### 주성분분석(Principal Component Analusis, PCA)

주성분분석은 데이터의 공분산행렬(covariance matrix)에 대한 고유값 분해에 기반을 둔 직교분해.



공분산 행렬에 대해 주성분분석(PCA)의 의미

C  = W D W<sup>T</sup>

- W: n차원 회전행렬(정규직교행렬)
- D: n차원 확대축소(확대축소 크기에 따른 정렬 형태)



## 벡터공간과 최소제곱법

집합(set)은 임의의 원소(element)를 수집해 만든 모음

집합이 닫혀있다 - 집합에서 임의의 원소를 뽑아 연산을 수행한 결과가 여전히 집합의 원소로 있을 경우



공간(space)은 다음의 두 연산에 닫혀 있는 집합

- 덧셈연산에 닫혀있다: 집합에서 임의의 두 원소 x, y를 뽑아 더해도 그 결과 x + y는 집합의 원소
- 스칼라 곱 연산에 닫혀있다: 집합에서 임의의 한 원소 x를 뽑아 임의의 스칼라 s배 한 결과 sx는 집합의 원소

앞으로 모든 n-벡터 집합 R<sup>n</sup>은 n차원 벡터 공간(vector space)라 부를 수 있다.



#### 열공간(column space)

행렬 A의 열벡터들에 대한 가능한 모든 선형조합의 결과를 모아 집합으로 구성 할 때, 이 집합을 열공간(column space)라 하고 `col(A)`라 표기

Ax = b에서 b가 열공간에 존재할 경우 -> 해가 있다.(consistent)

Ax = b에서 b가 열공간에 X -> 해가 없다.(inconsistent)



#### 최소제곱법의 의미

열공간으로 투영 -> 해가 없음에도 불구하고, 우리가 할 수 있는 최선 -> 근사치 해를 구하자.

달성가능한(b와 가장 가까운) 벡터를 통해 해를 구하자.



최소제곱법은 선형시스템 Ax = b에 대한 해 x가 없음에도 불구하고, 가능한 최선의 대안 X를 내놓는 기법.

최소제곱법은 원래의 선형시스템 Ax = b가 아닌, AX = B(X와 B는 열공간에 투영한 근사X, B)

이 방법은 원래의 목표b와 달성가능한 목표 B의 차이를 나타내는 벡터 (b - B)의 제곱길이를 최소화 시키는 의미를 가지기 때문에 `최소제곱법`이라 부른다.



#### 선형회귀

2차원 공간에 m개의 정점이 있을 때, 이를 잘 설명할 수 있는 직선 y = mx + b를 구하는 문제를 선형회귀(linear regression)문제라 한다.

1. 선형시스템 구성: 직선이 각 정점을 모두 지나간다고 가정하고 선형시스템 Ax = b를 구성(단 모든 정점을 지나지 않으므로 해는 존재 X)
2. 최소제곱법을 적용해 근사해 X를 구한다.

##### 해 X는 기존의 선형시스템의 해x와 다르다. 하지만 근사해.



## 통계학, 기본개념

#### 통계학(statistics)

- 데이터의 수집, 구성 분석, 해석 ,표현
- 기술통계학(descriptive statistics)
- 추측통계학(inferential statistics)



##### 모집단(population)

- 어떤 질문이나 실험을 위해 관심의 대상이 되는 개체나 사건의 집합
- ex.전교 남학생의 키

##### 모수(parameter)

- 모집단의 수치적인 특성
- ex.키의 평균

##### 표본(sample)

- 모집단에서 선택된 개체나 사건의 집합

#### 도수(Frequency)

- 정의
  - 어떤 사건이 실험이나 관찰로부터 발생한 횟수
- 표현 방법
  - 도수분포표(Frequency Distribution Table)
  - 막대그래프(Bar graph)
    - 질적 자료
  - 히스토그램(Histogram)
    - 양적자료 -> 구간을 통해 표현

- 줄기 잎 그림
  - 양적 자료를 줄기와 잎으로 구분
- 상대도수
  - 도수를 전체 원소의 수로 나누 ㄴ것



### scipy 모듈

- ##### 평균(mean)

- ```python
  import statistics
  statistics.mean(a)
  ```

- 모평균 u

  - 모집단 전체 자료일 경우

- 표본 평균 x
  - 모집단에서 추출한 표본일 경우



- ##### 중앙값

- ```python
  statistics.median(a)
  ```

  - 평균의 경우 극단 값의 영향을 많이 받음(ex. 1, 2, 3, 4, 5, 100000)
  - 주어진 자료를 높은 쪽 절반과 낮은 쪽 절반으로 나누는 값을 의미
  - 자료를 순서대로 나열했을 때 가운데 있는 값
  - 자료의 수:n 일 때, n이 홀수 면 (n + 1) / 2번째 값, n이 짝수면 n/2와 n/2 + 1번째 자료의 평균



- ##### 분산

- ```python
  statistics.variance(a)
  
  import scipy
  importscipy.stats
  scipy.stats.tvar(a)
  ```

  - 편차의 제곱의 합을 자료의 수로 나눈 값
    - 편차: 값과 평균의 차이
  - 모분산: 자료가 모집단일 경우
  - 표본분산: 자료가 표본일 경우



- ##### 표준편차(standard Deviation)

- ```python
  statistics.stdev(a)
  ```

  - 분산의 양의 제곱근
  - 모표준편차( population standard deviation)
  - 표본표준편차(sample standard deviation)



#### 모 vs 표준

N으로 나누냐, n-1로 나누냐

```python
import numpy
numpy.var(a) #-> 모분산
numpy.std(a) #-> 모표준편차
#ddof:Delta Degrees of Freedom
numpy.var(a, ddof=1)#-> 표본분산
numpy.std(a, ddof=1)#-> 표본표준편차
```



##### 범위(range)

- 자료를 정렬하였을 때 가장 큰 값과 가장 작은 값의 차이
  - max(a) - min(a)



##### 사분위수(Quartile)

- 전체 자료를 정렬했을 때, 1/4, 2/4, 3/4 위치에 있는 숫자
  - Q1:제 1사분위수
  - Q3: 제 3사분위수
  - numpy.quantile(a, .25)#.25번째에 해당하는 수 출력(어떤 숫자도 가능)
- 사분위범위(IQR, interquartile range)
  - Q3 - Q1
  - numpy.quantile(a, .75) - numpy.quantile(a, .25)



- ##### Z-SCORE
  - 어떤 값이 평균으로부터 몇 표준편차 떨어져 있는지를 의미하는 값
  -  scipy.stats.zscore(a) ->모표준편차로 나누기
  - scipy.stats.zscore(a, ddof=1) ->표본표준편차로 나누기

