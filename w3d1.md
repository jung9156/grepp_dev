## 통계적 추론

- 통계적 추론
  - 표본 조사를 통해 모집단에 대한 해석을 진행
  - 전수조사는 실질적으로 불가능한 경우가 많음
- 표존 보사는 반드시 오차가 발생
  - 적절한 표본 추출 방법 필요
  - 표본과 모집단의 관계를 이해해야 함



- 단순랜덤추출법(random sampling)
- 난수표 사용
- 랜덤넘버 생성기 사용

```python
import random
[random.randint(1, 1000) for i in range(10)]
```



#### 표본 분포

표본 평균의 분포 -> 모집단에서 표본을 뽑아 통계 처리를 하는데, 표본은 뽑을 때 마다 달라진다. 이런 표본이 가지는 값에 대해서 대체적으로 어떤 분포를 따르는가를 알게 된다면 해석에 용이하다.



- 표본 조사를 통해 파악하고자 하는 정보
  - 모수(parameter)
- 모수의 종류:
  - -모평균, 모분산, 모비율 등
  - 모수를 추정하기 위해 표본을 선택하여 표본 평균이나 표본 분산 등을 계산
- 통계량(statistic)
  - 표본 평균이나 표본 분산과 같은 표본의 특성값
- 50만명의 전국 고등학교 1학년 학생의 키를 조사하기 위해 1000명을 표본 조사함
  - 표본의 평균 계산
  - 표본의 평균은 표본의 선택에 따라 달라짐
  - 따라서 표본평균은 확률변수
- 표본 평균이 가질 수 있는 값도 하나의 확률분포를 가짐
  - 그 분포가 무엇인지가 표본을 해석하는데 있어서 매우 중요함
- 통계량의 확률분포: 표본분포(sampling distribution)



- 표본 평균
  - 모평균을 알아내는데 쓰이는 통계량
- 표본 평균의 분포
  - x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>, ...,  x<sub>n</sub>
    - 평균 : μ
    - 분산: σ<sup>2</sup>
    - 정규모집단에서 추출된 표본의 측정값
  - 표본평균
    - 평균X = sum(x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>, ...,  x<sub>n</sub>) / n
    - 평균X~ N = (μ, σ<sup>2</sup> / n)



#### 중심극한정리(central limit theorem)

- n이 충분히 크면(>= 30) 근사적으로 정규분포를 따른다.

- x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>, ...,  x<sub>n</sub>
  - 평균 : μ
  - 분산: σ<sup>2</sup>
  - ~~정규~~`모집단`에서 추출된 표본의 측정값
- 표본평균
  - 평균X = sum(x<sub>1</sub>, x<sub>2</sub>, x<sub>3</sub>, ...,  x<sub>n</sub>) / n
  - 평균X~ N = (μ, σ<sup>2</sup> / n)
    - 근사적으로 X~N (μ, σ<sup>2</sup> / n) 인 정규분포를 따름





## 추정

- 표본평균의 특성
  - 모집단이 정규분포인 경우
    - 표본평균 사용
  - 대표본인 경우
    - 중심극한 정리에 의해 표본평균이 정규분포를 따른다고 가정함
- 점추정
  - 표본평균이 점 추정값(추정량)이 됨

- 구간추정
  - 모평균 μ의 100(1 - α)% 신뢰구간(confidence interval)
    - (μ의 추정량) +- Z<sub>α/2</sub> (추정량의 표준편차)
  - 실용적이지 못함 : 정규분포가 아니거나 표준편차가 알려져 있지 않음
- 표본의 크기가 클 때, 중심극한 정리 사용
  - s: 표본표준편차
    - (μ의 추정량) +- Z<sub>α/2</sub> (추정량의 표준편차)
- 어떤 학교의 고1 남학생의 평균키를 추정하기 위해 36명을 표본으로 추출하여 그 표본평균과 표본표준편차를 계산하여 그 결과가 아래와 같다.
- 평균 = 173.6, s = 3.6
- 평균키에 대한 95% 신뢰 구간을 구하시오
  - α = 0.05
  - Z<sub>α/2</sub> = Z<sub>0.025</sub> = 1.96
  - (Z<sub>α/2</sub> * s) / n<sup>1/2</sup> = (1.96 * 3.6) / 36<sup>1/2</sup> = 1.176
  - 95% 신뢰 구간
    - (173.6 - 1.176, 173.6 + 1.176) = (172.4, 174.8)



#### 모비율의 추정

- 점 추정
  - 확률변수 X:
    - n개의 표본에서 특정 속성을 갖는 표본의 개수
  - 모비율 p의 점추정량
    - p = X / n
- 대학교 1학년생의 흡연율을 조사하기 위해 150명명을 랜덤하게 선택하여 흡연여부를 조사하였다. 이 중 48명이 흡연을 하고 있었다. 이 대학교 1학년생의 흡연율의 평균을 점추정하시오.
- n = 150
- X = 48
- p = 48 / 150 = 0.32
- 평균흡연율 32%로 추정됨



- 구간추정
  - n이 충분히 클 때,
    - np > 5, n(1-p) > 5일 때를 의미
    - X~N(np, np(1-p))
  - 확률변수 X의 표준화
    - Z = (x - np) / (np(1-p))<sup>1/2</sup>
    - 근사적으로 표준정규분포 N(0, 1)를 따름
  - P(|Z| <= Z<sub>α/2</sub>) = 1 - α
  - 모비율 p의 100(1 - α)% 신뢰구간(confidence interval)
  - (P - Z<sub>α/2</sub>(P(91 - p)/n)<sup>1/2</sup>, P + Z<sub>α/2</sub>(P(91 - p)/n)<sup>1/2</sup>)



## 검정

#### 통계적 가설 검정

- 가설검정
  - 어떤 고등학교의 1학년 학생들의 평균키가 170.5 cm로 알려져 있었다. 올해 새로 들어온 1학년 학생들 중 30명을 랜덤하게 선택하여 키를 잰 후 평균을 계산했더니 171.3cm였다.
  - 올해 신입생은 평균키가 170.5cm보다 더 크다고 할 수 있는가?
- 이러한 주장을 검증하는 것이 가설 검정임
- 표본평균 X가 μ<sub>0</sub>보다 얼마나 커야 모평균 μ가 μ<sub>0</sub>보다 크다고 할 수 있을 것인가?
  - 표본평균은 표본의 선택에 의해 달라짐에 주의



- 가설 검정
  - 귀무가설  H<sub>0</sub> :  μ = μ<sub>0</sub>
  - 대립가설  H<sub>1</sub> :  μ > μ<sub>0</sub>
  - 귀무가설을 기각하기 위해서는 X가 좀 큰 값이 나와야 함.
    - 귀무가설이 참이라고 가정할 때, 랜덤하게 선택한 표본에서 지금의 X가 나올 확률을 계산할 필요
    - 이 확률이 낮다면 귀무가설이 참이 아니라고 판단
  - 확률이 낮다는 기준점 필요
    - 유의수준 α 도입
    - P(X >= k) <= α가 되는 k를 찾아야 함
    - 표준정규확률변수로 변환 -> 검정통계량이라고 함
      - Z = (X - μ) / (S / n<sup>1/2</sup>) ~ N (0, 1)
      - P(Z >= z<sub>α</sub>) = α
    - 따라서  X를 Z로 변환한 후 Z값이 z<sub>α</sub>보다 큰지를 검토
      - 크다면 귀무가설 기각
      - 그렇지 않다면 귀무가설 채택
- 정리
  - 검정의 단계
    - H<sub>0</sub>, H<sub>1</sub> 설정
    - 유의수준 α 설정
    - 검정통계량 계산
    - 기각역 또는 임계값 계산
    - 주어진 데이터로부터 유의성 판정



#### 모평균의 검정

- 대립가설

  - 문제에서 검정하고자 하는 것이 무엇인지 파악 필요
    - 대립가설 H<sub>1</sub>채택을 위한 통계적 증거 확보 필요
    - 증거가 없으면 귀무가설 H<sub>0</sub> 채택
    - H<sub>1</sub> :  μ > μ<sub>0</sub>
    - H<sub>1</sub> :  μ < μ<sub>0</sub>
    - H<sub>1</sub> :  μ != μ<sub>0</sub>
  - 어떤 농장에서 생산되는 계란의 평균 무게는 10.5그램으로 알려져 있다. 새로운 사료를 도입한 후에 생산된 계란 30개의 표본평균을 계산했더니 11.4그램이 나왔다. 새로운 사료가 평균적으로 더 무거운 계란을 생산한다고 할 수 있는가?
    - H<sub>0</sub> :  μ = 10.5
    - H<sub>1</sub> :  μ > 10.5

  

  - 어떤 농장에서 생산되는 계란의 평균 무게는 10.5그램으로 알려져 있다. 새로운 사료를 도입한 후에 생산된 계란 30개의 표본평균을 계산했더니 9.4그램이 나왔다. 새로운 사료가 평균적으로 더 가벼운 계란을 생산한다고 할 수 있는가?
    - H<sub>0</sub> :  μ = 9.4
    - H<sub>1</sub> :  μ < 9.4
  - 어떤 농장에서 생산되는 계란의 평균 무게가 10.5그램이라고 홍보하고 있다. 이에 생산된 계란 30개의 표본 평균을 계산했더니 9.4그램이 나왔다. 이 농장의 광고가 맞다고 할 수 있는가?
    - H<sub>0</sub> :  μ = 10.5
    - H<sub>1</sub> :  μ != 10.5



#### 검정 통계량

- n >= 30인 경우
  - 중심극한 정리 사용
- 모집단이 정규 모집단이고, 모표준편차 σ가 주어진 경우
  - 분포를 구할 수 있다.
- 기타의 경우는 본 강의의 범위를 벗어남

- 기각역
  - H<sub>0</sub> : μ = 10.5
  - 유의수준 : α
  - 기각역
  - H<sub>1</sub> : μ > 10.5 -> Z > z<sub>α</sub>
  - H<sub>1</sub> : μ < 10.5 -> Z < z<sub>α</sub>
  - H<sub>1</sub> : μ != 10.5 -> |Z| > z<sub>α/2</sub>
- 검정의 예
  - 평균 10.43, 표준편차 1.11
  - 검정 통계량 -0.3454488....
  - 임계값 1.9599639...
  - 임계값 > |검정통계량| -> 귀무가설 기각 X
- 검정의 예 2
  - 평균 9.93, 표준편차 1.11
  - 검정 통계량 -2.81294033.....
  - 임계값 1.9599639...
  - 임계값 < |검정통계량| -> 귀무가설 기각



## 엔트로피

- 자기정보(self information): i(A)
  - A : 사건
  - i(A) = log<sub>b</sub>(1 / P(A)) = -log<sub>b</sub>P(A)
  - 확률이 높은 사건: 확률이 높으면 자주 일어나는 사건 - 정보가 많지 않다.
    - 정보가 많지 않음
      - ex. 도둑이 들었는데 개가 짖는 경우보다 도둑이 들었는데 개가 안 짖는 경우 더 많은 정보를 포함하고 있음
    - 정보의 단위
      - b = 2: bits
      - b = e: nats
      - b = 10 : hartleys
- 특성
  - i(AB) = i(A) + i(B)
- P(H) = 1 / 8, P(T) = 7 / 8
- i(H) = 3비트, i(T) = 0.193 비트 - > 사건이 나올 확률로 정보의 양을 표현



#### 엔트로피

- 자기 정보의 평균 H(X)
- 특성
  - 0 <= H(X) <= log<sub>2</sub>K, K = 사건의 수
- 엔트로피의 활용
  - 평균비트수를 표현
  - 데이터 압축에 사용 가능
- 4가지 정보를 표현하는데 필요한 비트수
  - 일반적으로 2비트
  - i(X)를 활용하는 경우
    - 평균비트수
      - 1 x 1/2 + 2 x 1/4 + 3 x 1/8 + 3 x 1/8 = 14 / 8 = 7 / 4비트
- 확률분포 P와 Q
  - S = {A<sub>j</sub>}
    - P(A<sub>j</sub>) : 확률분포 P에서 사건 A<sub>j</sub>가 발생할 확률
    - Q(A<sub>j</sub>) : 확률분포 Q에서 사건 A<sub>j</sub>가 발생할 확률
    - i(A<sub>j</sub>) : 확률분포 Q에서 사건 A<sub>j</sub>의 자기정보
      - i(A<sub>j</sub>) = -log<sub>2</sub>Q(A<sub>j</sub>)
      - 자기 정보는 A<sub>j</sub>를 표현하는 비트수
      - 잘못된 확률분포 Q를 사용하게 되면, 실제 최적의 비트수를 사용하지 못하게 됨
- 교차엔트로피
  - H(P, Q)
    - 집합 S상에서 확률분포 P에 대한 확률분포 Q의 교차 엔트로피
    - 확률분포 P에서 i(A<sub>j</sub>)의 평균
      - 이 값은 정확한 확률분포 P를 사용했을 때의 비트수보다 크게 됨
    - 따라서 이 값은 P와 Q가 얼마나 비슷한지를 표현
      - 같으면 H(P, Q) = H(P)
      - 다르면 H(P, Q) > H(P)

- 분류 분제에서의 손실함수
  - 분류문제
    - 주어진 대상이 A인지 아닌지를 판단
    - 주어진 대상이 A, B, C, .... 중 어느 것인지를 판단
  - 기곅학습에서는 주어진 대상이 각 그룹에 속할 확률을 제공
    - ex.[0.8, 0.2] : A일 확률 0.8, 아닐확률 0.2
    - 이 값이 정답인 [1.0, 0.0]과 얼마나 다른지 측정 필요
  - 원하는 답 P = [p1, p2, ... pn], p1 + p2 + ... + pn = 1
  - 제시된 답 Q = [q1, q2, ..., qn], q1 + q2 + ... + qn = 1
  - P와 Q가 얼마나 다른지에 대한 척도 필요
  - 제곱합
    - (P<sub>i</sub>- q<sub>i</sub>)^2의 합
    - 확률이 다를수록 큰 값을 가짐
    - 하지만 학습 속도 느림
  - 교차 엔트로피 H(P, Q):
    - 확률이 다를수록 큰 값을 가짐
    - 학습 속도 빠름
    - 분류 문제에서 주로 교차 엔트로피 사용
  - 분류 문제에서의 원하는 답
    - P<sub>i</sub> 중 하나만 1이고, 나머지는 다 0임
      - 엔트로피는 0, 즉 H(P) = 0
    - p<sub>k</sub> = 1.0 이라고 하면, q<sub>k</sub>의 값이 최대한 커지는 방향으로 학습 진행



